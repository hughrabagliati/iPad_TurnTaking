<<<<<<< Updated upstream
qnorm(0.5)
qnorm(0.975) - qnorm(16)
qnorm(0.975) - qnorm(0.16)
qnorm(0.84) - qnorm(0.5)
qnorm(0.975) - qnorm(0.84)
qnorm(0.50) - qnorm(0.16)
setwd("~/")
load("~/Dropbox/ETAutism/ET_Mar26-2013.RDATA")
# Data Analysis Scripts
# Function to shuffle condition labels assuming that we hold groups of trials constant. i.e., does the same as shuffling averaged data.
# Function to shuffle the condition label then compute the same stats as above
# This does the resampling on your data.
resample = function(data_file,StartTime,EndTime,StepSize){
summaryBy(Trial~Subj+Trial+Cond+Strength+Pop, data = data_file ) -> Trials
shuf.fnc <- function(x){
NewCond <- x$Cond[sample.int(length(x$Cond))]
NewStrength <- x$Strength[sample.int(length(x$Strength))]
return(data.frame(x,NewCond,NewStrength))
}
Trials = ddply(Trials, .(Subj), shuf.fnc)
for (i in unique(data_file$Subj)){
data_file_S = data_file[data_file$Subj == i,]
data_file_S.prac = data_file_S
for (j in unique(data_file_S.prac$Trial)){
data_file_S[ data_file_S.prac$Trial == j,]$Cond =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewCond),length(data_file_S[ data_file_S.prac$Trial == j,]$Cond))
data_file_S[ data_file_S.prac$Trial == j,]$Strength =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewStrength),length(data_file_S[ data_file_S.prac$Trial == j,]$Strength))
}
data_file[data_file$Subj == i,] = data_file_S
}
Trials <- summaryBy(Subj~Subj+Pop, data = Trials)
Trials$Order = NA
Trials$Order = sample.int(length(Trials$Order),length(Trials$Order))
Trials$Pop = Trials[order(Trials$Order),]$Pop
#print(Trials$Pop)
for (i in unique(data_file$Subj)){
data_file[data_file$Subj == i,]$Pop = Trials[Trials$Subj == i,]$Pop
}
data_file$Cond = as.factor(data_file$Cond)
data_file$Strength = as.factor(data_file$Strength)
data_file$Pop = as.factor(data_file$Pop)
contrasts(data_file$Cond)[1] <- -1
contrasts(data_file$Cond)[2] <- 1
contrasts(data_file$Strength)[2] <- 1
contrasts(data_file$Strength)[1] <- -1
contrasts(data_file$Pop)[2] <- 1
contrasts(data_file$Pop)[1] <- -1
#	print(data_file[data_file$Subj == i,]$Pop[1:30])
#       print(data_file[data_file$Subj == i,]$Trial[seq(300,1000, by = 25)])
#        print(data_file[data_file$Subj == i,]$Cond[seq(300,1000, by = 25)])
#        print(data_file[data_file$Subj == i,]$Strength[seq(300,1000, by = 25)])
#        print(data_file[data_file$Subj == i,]$Score[seq(300,1000, by = 25)])
stats.resample = calculate.statistics(data_file,StartTime,EndTime,StepSize)
return(stats.resample)
}
# Cluster finding function and pval finding function
# Cluster finding script (written by Jon Brennan )
find.clusters <- function(pval.vector, tval.vector, latencies, alpha=.05, cluster.size=5,signed =FALSE, sign = "pos") {
binary.stat <- as.numeric(pval.vector < alpha)
tval.stat <- rep(0,length(binary.stat))
tval.stat[2:length(binary.stat)] = ((tval.vector[2:length(binary.stat)] * tval.vector[1:(length(binary.stat)-1)]) <0)
cluster.start <- c()
cluster.end <- c()
cluster.stat <- c()
in.cluster <- 0
found.clusters <- 0
new.end <- 0
new.start <- 0
end.cluster <- 0
for (n in 1:length(binary.stat)) {
if (signed == FALSE){
if (in.cluster == 0 && binary.stat[n] == 1 ) {
new.start = n
in.cluster = 1
}
}else
if (sign == "pos"){
if (in.cluster == 0 && binary.stat[n] == 1 && tval.vector[n] >= 0) {
new.start = n
in.cluster = 1
}
}else
if (in.cluster == 0 && binary.stat[n] == 1 && tval.vector[n] <= 0) {
new.start = n
in.cluster = 1
}
if (in.cluster == 1 && binary.stat[n] == 0) {
new.end = n
end.cluster = 1
in.cluster = 0
}
if (in.cluster == 1 && tval.stat[n] == 1) {
new.end = n
end.cluster = 1
in.cluster = 0
}
# in case we reach the end and we are still "in" a cluster...
if (in.cluster == 1 && binary.stat[n] == 1 && n == length(binary.stat)) {
new.end = n
end.cluster = 1
in.cluster = 1
}
if (end.cluster) {
if ((new.end - new.start) >= cluster.size) {
found.clusters <- found.clusters + 1
cluster.start<- c(cluster.start, latencies[new.start])
cluster.end <- c(cluster.end, latencies[new.end])
cluster.stat <- c(cluster.stat, sum(abs(tval.vector[new.start:(new.end-1)])))
}
end.cluster = 0
}
}
cluster.out <- data.frame(start = cluster.start, end = cluster.end, cluster.stat = cluster.stat)
return(cluster.out)
}
# Script for assigning pvals to clusters
pval = function(sample.cluster,resample.large.cluster){
sample.cluster$pval = 1
for (i in 1:length(sample.cluster$cluster.stat)){
print(i)
sample.cluster$pval[i] = 1 - sum(as.numeric(sample.cluster$cluster.stat[i]>resample.large.cluster)/Resamples_N)
}
return(sample.cluster)
}
# What analysis will we be doing at each time point?
calculate.statistics = function(data_file,StartTime,EndTime,StepSize){
#Load the relevant libraries
require("lme4")
require(multicore)
require(doMC)
require(foreach)
require(plyr)
#Start the multicore machine!
#Split the data frame into a list for each timepoint
a = split(data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,],data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,]$Time)
#Parallel application of lmer and coefficient extraction, outputs another list as above
mclapply(a,function(x) coef(summary(lmer(Score~Cond*Strength*Pop +(1+Cond*Strength|Subj) , data = x)))[2:8,1:3]) -> a.co
# Evaluate the list to see whether t value meets a threshold (hard coded)
lapply(a.co,function(x) data.frame(x,pv = ifelse(abs(x[,3]) > 1.6,0.04,0.06), co = rownames(x))) -> k
# plyr that list into a dataframe
k.df = ldply(k)
k.df$.id = as.numeric(k.df$.id)
colnames(k.df) <- c("Time", "Estimate","SE", "Stat", "pval","Coef")
k.df$Coef = ordered(k.df$Coef,levels = c("CondU","Strengthweak","PopControl","CondU:Strengthweak","CondU:PopControl","Strengthweak:PopControl", "CondU:Strengthweak:PopControl"))
#Split that dataframe into a list based on the regression coefficients
stats.sample = split(k.df,k.df$Coef)
return(stats.sample)
}
# What analysis will we be doing at each time point?
calculate.statistics.nopop = function(data_file,StartTime,EndTime,StepSize){
require("lme4")
require(multicore)
require(doMC)
require(foreach)
require(plyr)
a = split(data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,],data_file[data_file$Time >= 0 & data_file$Time <= 1500,]$Time)
mclapply(a,function(x) coef(summary(lmer(Score~Cond*Strength +(1+Cond+Strength|Subj) + (1+Cond+Strength|Trial), data = x)))[2:4,1:3]) -> a.co
lapply(a.co,function(x) data.frame(x,pv = ifelse(abs(x[,3]) > 1.6,0.04,0.06), co = rownames(x))) -> k
k.df = ldply(k)
k.df$.id = as.numeric(k.df$.id)
colnames(k.df) <- c("Time", "Estimate","SE", "Stat", "pval","Coef")
k.df$Coef = ordered(k.df$Coef,levels = c("CondU","Strengthweak","CondU:Strengthweak"))
stats.sample = split(k.df,k.df$Coef)
return(stats.sample)
}
pval = function(sample.cluster,resample.large.cluster){
sample.cluster$pval = 1
for (i in 1:length(sample.cluster$cluster.stat)){
print(i)
sample.cluster$pval[i] = 1 - sum(as.numeric(sample.cluster$cluster.stat[i]>resample.large.cluster)/Resamples_N)
}
return(sample.cluster)
}
# Data Analysis Scripts
# Function to shuffle condition labels assuming that we hold groups of trials constant. i.e., does the same as shuffling averaged data.
# Function to shuffle the condition label then compute the same stats as above
# This does the resampling on your data.
resample.nopop = function(data_file,StartTime,EndTime,StepSize){
summaryBy(Trial~Subj+Trial+Cond+Strength+Pop, data = data_file ) -> Trials
Trials$Order = NA
Trials$NewCond = Trials$Cond
Trials$NewStrength = Trials$Strength
Trials$NewPop = Trials$Pop
for (i in unique(Trials$Subj)){
Trials[Trials$Subj == i,]$Order = sample.int(length(Trials[Trials$Subj == i,]$Cond),length(Trials[Trials$Subj == i,]$Cond))
Trials[Trials$Subj == i,]$NewCond = Trials[ order(Trials[Trials$Subj == i,]$Order),]$Cond
#Trials[Trials$Subj == i,]$NewOrder = sample.int(length(Trials[Trials$Subj == i,]$Cond),length(Trials[Trials$Subj == i,]$Cond))
Trials[Trials$Subj == i,]$NewStrength = Trials[ order(Trials[Trials$Subj == i,]$Order),]$Strength
}
for (i in unique(data_file$Subj)){
data_file_S = data_file[data_file$Subj == i,]
data_file_S.prac = data_file_S
for (j in unique(data_file_S.prac$Trial)){
data_file_S[ data_file_S.prac$Trial == j,]$Cond =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewCond),length(data_file_S[ data_file_S.prac$Trial == j,]$Cond))
data_file_S[ data_file_S.prac$Trial == j,]$Strength =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewStrength),length(data_file_S[ data_file_S.prac$Trial == j,]$Strength))
}
data_file[data_file$Subj == i,] = data_file_S
}
Trials <- summaryBy(Subj~Subj+Pop, data = Trials)
Trials$Order = NA
Trials$Order = sample.int(length(Trials$Order),length(Trials$Order))
Trials$Pop = Trials[order(Trials$Order),]$Pop
#print(Trials$Pop)
for (i in unique(data_file$Subj)){
data_file[data_file$Subj == i,]$Pop = Trials[Trials$Subj == i,]$Pop
}
data_file$Cond = as.factor(data_file$Cond)
data_file$Strength = as.factor(data_file$Strength)
data_file$Pop = as.factor(data_file$Pop)
contrasts(data_file$Cond)[1] <- -1
contrasts(data_file$Cond)[2] <- 1
contrasts(data_file$Strength)[2] <- 1
contrasts(data_file$Strength)[1] <- -1
#contrasts(data_file$Pop)[2] <- 1
#contrasts(data_file$Pop)[1] <- -1
#	print(data_file[data_file$Subj == i,]$Pop[1:30])
#       print(data_file[data_file$Subj == i,]$Trial[seq(300,1000, by = 25)])
#        print(data_file[data_file$Subj == i,]$Cond[seq(300,1000, by = 25)])
#        print(data_file[data_file$Subj == i,]$Strength[seq(300,1000, by = 25)])
#        print(data_file[data_file$Subj == i,]$Score[seq(300,1000, by = 25)])
stats.resample = calculate.statistics.nopop(data_file,StartTime,EndTime,StepSize)
return(stats.resample)
}
StartTime = 0
EndTime = 1500
StepSize = 100
# Get the relevant stats for your data file.
registerDoMC();
stats.sample = calculate.statistics(ET,StartTime,EndTime,StepSize)
stats.sample
install.packages(c("pbkrtest", "sp"))
setwd("~/GitHub/iPad_TurnTaking/DistrAnalyses/STAN_Analysis")
library(retimes)
library(rstan)
ads <- read.csv("Adult_R.csv")
fives <- read.csv("5yo_R.csv")
threes <- read.csv("3yo_R.csv")
ads$Age <- "Adult"
fives$Age <- "Five"
threes$Age <- "Three"
tt <- rbind(ads,fives,threes)
tt$Age <- as.factor(tt$Age)
tt$Subject <- paste(tt$Age,tt$Participant, sep = "")
tt<- subset(tt, RTms <= 8000)
tt$rt <- tt$RTms
tt$N_Match <- ifelse(tt$Match == "Match",0,1)
tt$N_Pred <- ifelse(tt$Pred == "Pred",0,1)
tt$N_AgeFive <- model.matrix(~tt$Age)[,2]
tt$N_AgeThree <- model.matrix(~tt$Age)[,3]
tt$N_M_P_Interact <- tt$N_Pred * tt$N_Match
tt$N_Match_AgeFive_Interact <-  tt$N_Match * tt$N_AgeFive
tt$N_Match_AgeThree_Interact <- tt$N_Match * tt$N_AgeThree
tt$N_Pred_AgeFive_Interact <- tt$N_Pred * tt$N_AgeFive
tt$N_Pred_AgeThree_Interact <- tt$N_Pred * tt$N_AgeThree
tt$N_Match_Pred_AgeFive_Interact <- tt$N_Match * tt$N_Pred * tt$N_AgeFive
tt$N_Match_Pred_AgeThree_Interact <- tt$N_Match * tt$N_Pred * tt$N_AgeThree
# For some reason, model won't converge with RTs above zero?
tt$rt_scale <- (tt$rt - mean(tt$rt,na.rm = T))/sd(tt$rt, na.rm = T)
tt$rt <- tt$rt + abs(min(tt$rt))
# Fit Ex-Gaussian using ML (retimes library)
eg_ml <- timefit(tt$rt)
print(eg_ml)
timefit(tt$rt_scale)
stanDat <- list(rt = tt$rt_scale,factor1 = tt$N_Match,factor2 = tt$N_Pred,factor3 = tt$N_AgeFive,factor4 = tt$N_AgeThree, N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan <- stan(file="fixEf_Age_and_Conds_priors_on_mu.stan",
data=stanDat,
iter=500, warmup = 200, chains = 1)
print(eg_stan, pars = c("beta","beta_s","beta_t"), probs = c(0.025,0.5,0.975))
stanDat <- list(rt = tt$rt_scale,factor1 = tt$N_Match,factor2 = tt$N_Pred,factor3 = tt$N_AgeFive,factor4 = tt$N_AgeThree, N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan <- stan(file="fixEf_Age_and_Conds_priors_on_mu.stan",
data=stanDat,
iter=500, warmup = 200, chains = 1)
print(eg_stan, pars = c("beta","beta_s","beta_t"), probs = c(0.025,0.5,0.975))
stanDat <- list(rt = tt$rt_scale,factor1 = tt$N_Match,factor2 = tt$N_Pred,factor3 = tt$N_AgeFive,factor4 = tt$N_AgeThree, N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan <- stan(file="fixEf_Age_and_Conds_priors_on_mu.stan",
data=stanDat,
iter=500, warmup = 200, chains = 1)
print(eg_stan, pars = c("beta","beta_s","beta_t"), probs = c(0.025,0.5,0.975))
stanDat <- list(rt = tt$rt_scale,factor1 = tt$N_Match,factor2 = tt$N_Pred,factor3 = tt$N_AgeFive,factor4 = tt$N_AgeThree, N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan <- stan(file="fixEf_Age_and_Conds_priors_on_mu.stan",
data=stanDat,
iter=500, warmup = 200, chains = 1)
print(eg_stan, pars = c("beta","beta_s","beta_t"), probs = c(0.025,0.5,0.975))
stanDat <- list(rt = tt$rt_scale,factor1 = tt$N_Match,factor2 = tt$N_Pred,factor3 = tt$N_AgeFive,factor4 = tt$N_AgeThree, N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan <- stan(file="fixEf_Age_and_Conds_priors_on_mu.stan",
data=stanDat,
iter=500, warmup = 200, chains = 1)
print(eg_stan, pars = c("beta","beta_s","beta_t"), probs = c(0.025,0.5,0.975))
stanDat <- list(rt = tt$rt_scale,factor1 = tt$N_Match,factor2 = tt$N_Pred,factor3 = tt$N_AgeFive,factor4 = tt$N_AgeThree, N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan <- stan(file="fixEf_Age_and_Conds_priors_on_mu.stan",
data=stanDat,
iter=500, warmup = 200, chains = 1)
print(eg_stan, pars = c("beta","beta_s","beta_t"), probs = c(0.025,0.5,0.975))
stanDat <- list(rt = tt$rt_scale,factor1 = tt$N_Match,factor2 = tt$N_Pred,factor3 = tt$N_AgeFive,factor4 = tt$N_AgeThree, N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan <- stan(file="fixEf_Age_and_Conds_priors_on_mu.stan",
data=stanDat,
iter=500, warmup = 200, chains = 1)
print(eg_stan, pars = c("beta","beta_s","beta_t"), probs = c(0.025,0.5,0.975))
stanDat <- list(rt = tt$rt_scale,factor1 = tt$N_Match,factor2 = tt$N_Pred,factor3 = tt$N_AgeFive,factor4 = tt$N_AgeThree, N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan <- stan(file="fixEf_Age_and_Conds_priors_on_mu.stan",
data=stanDat,
iter=500, warmup = 200, chains = 1)
print(eg_stan, pars = c("beta","beta_s","beta_t"), probs = c(0.025,0.5,0.975))
stanDat <- list(rt = tt$rt_scale,factor1 = tt$N_Match,factor2 = tt$N_Pred,factor3 = tt$N_AgeFive,factor4 = tt$N_AgeThree, N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan <- stan(file="fixEf_Age_and_Conds_priors_on_mu.stan",
data=stanDat,
iter=500, warmup = 200, chains = 1)
print(eg_stan, pars = c("beta","beta_s","beta_t"), probs = c(0.025,0.5,0.975))
stanDat <- list(rt = tt$rt_scale,factor1 = tt$N_Match,factor2 = tt$N_Pred,factor3 = tt$N_AgeFive,factor4 = tt$N_AgeThree, N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan <- stan(file="fixEf_Age_and_Conds_priors_on_mu.stan",
data=stanDat,
iter=500, warmup = 200, chains = 1)
print(eg_stan, pars = c("beta","beta_s","beta_t"), probs = c(0.025,0.5,0.975))
stanDat <- list(rt = tt$rt_scale,factor1 = tt$N_Match,factor2 = tt$N_Pred,factor3 = tt$N_AgeFive,factor4 = tt$N_AgeThree, N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan <- stan(file="fixEf_Age_and_Conds_priors_on_mu.stan",
data=stanDat,
iter=500, warmup = 200, chains = 1)
print(eg_stan, pars = c("beta","beta_s","beta_t"), probs = c(0.025,0.5,0.975))
stanDat <- list(rt = tt$rt_scale,factor1 = tt$N_Match,factor2 = tt$N_Pred,factor3 = tt$N_AgeFive,factor4 = tt$N_AgeThree, N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan <- stan(file="fixEf_Age_and_Conds_priors_on_mu.stan",
data=stanDat,
iter=500, warmup = 200, chains = 1)
stanDat <- list(rt = tt$rt_scale,factor1 = tt$N_Match,factor2 = tt$N_Pred,factor3 = tt$N_AgeFive,factor4 = tt$N_AgeThree, N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan <- stan(file="fixEf_Age_and_Conds_priors_on_mu.stan",
data=stanDat,
iter=500, warmup = 200, chains = 1)
# STAN model for ex-Gaussian fit - Age and Conds
stanDat <- list(rt = tt$rt_scale,factor1 = tt$N_Match,factor2 = tt$N_Pred,factor3 = tt$N_AgeFive,factor4 = tt$N_AgeThree, N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan <- stan(file="fixEf_Age_and_Conds_priors_on_mu.stan",
data=stanDat,
iter=500, warmup = 200, chains = 1)
# STAN model for ex-Gaussian fit - Age and Conds
stanDat <- list(rt = tt$rt,factor1 = tt$N_Match,factor2 = tt$N_Pred,factor3 = tt$N_AgeFive,factor4 = tt$N_AgeThree, N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan <- stan(file="fixEf_Age_and_Conds_priors_on_mu.stan",
data=stanDat,
iter=500, warmup = 200, chains = 1)
# STAN model for ex-Gaussian fit - Age and Conds
stanDat <- list(rt = tt$rt,factor1 = tt$N_Match,factor2 = tt$N_Pred,factor3 = tt$N_AgeFive,factor4 = tt$N_AgeThree, N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan <- stan(file="fixEf_Age_and_Conds_priors_on_mu.stan",
data=stanDat,
iter=500, warmup = 200, chains = 1)
print(eg_stan, pars = c("beta","beta_s","beta_t"), probs = c(0.025,0.5,0.975))
# STAN model for ex-Gaussian fit - Age and Conds
stanDat <- list(rt = tt$rt,factor1 = tt$N_Match,factor2 = tt$N_Pred,factor3 = tt$N_AgeFive,factor4 = tt$N_AgeThree, N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan <- stan(file="fixEf_Age_and_Conds_priors_on_mu.stan",
data=stanDat,
iter=500, warmup = 200, chains = 1)
print(eg_stan, pars = c("beta","beta_s","beta_t"), probs = c(0.025,0.5,0.975))
=======
data_diff <- orig_data  %>% mutate(D_Diff = D.mean - lag(D.mean, default = 0)) %>% filter(delay == "6") %>% group_by(cond) %>% summarize(low=quantile(D_Diff, alpha / 2), high=quantile(D_Diff, 1 - alpha / 2))
orig_data <- orig_data %>% group_by(cond,delay) %>% summarize(low=quantile(D.mean, alpha / 2),
high=quantile(D.mean, 1 - alpha / 2))
orig_summary <- full_join(orig_summary,orig_data, by = c("cond","delay"))
orig_summary$diff <- c(filter(data_diff,cond == "assoc")$low,filter(data_diff,cond == "assoc")$high,filter(data_diff,cond == "comp")$low,filter(data_diff,cond == "comp")$high)
return(orig_summary)
}
library(ez)
library(jsonlite)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(doBy)
## for bootstrapping 95% confidence intervals -- from Mike Frank https://github.com/langcog/KTE/blob/master/mcf.useful.R
library(bootstrap)
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)} #  mean(x,na.rm=na.rm) -
ci.high <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) } #- mean(x,na.rm=na.rm)}
Test_Import = function(path_name){
library(jsonlite)
list.files(path = path_name,full.names = T, pattern = ".txt") -> file_list
comp = c()
for (x in file_list){
file_name = x
df <- fromJSON(file_name)
d <- df$data[4]$trialdata[df$data[4]$trialdata$Screen == "judge",]
d <- d[ grep("categorize",d$trial_type, ignore.case = TRUE),]
d <- d[,!names(d)%in% "choices"]
d$Score = ifelse(d$key_press == d$corr_key, 1,0)
comp = rbind(comp,d)
print(x)
}
return(comp)
}
Mem_Import = function(path_name){
library(jsonlite)
list.files(path = path_name,full.names = T, pattern = ".txt") -> file_list
comp = c()
for (x in file_list){
file_name = x
df <- fromJSON(file_name)
d <- df$data[4]$trialdata[df$data[4]$trialdata$Screen == "probe",]
d <- d[ grep("button-response",d$trial_type, ignore.case = TRUE),]
d$Resp = NA
for (i in 1:length(d$Resp)){
choice = d$button_pressed[i] + 1
d$Resp[i] = d$choices[[i]][choice]
}
d$Resp <- as.factor(d$Resp)
d$RespCode = NA
if (length(d[d$Resp == d$correct,]$RespCode) > 0){d[d$Resp == d$correct,]$RespCode = "correct"}
if (length(d[d$Resp == d$w1_mm,]$RespCode) > 0){d[d$Resp == d$w1_mm,]$RespCode = "w1_mm"}
if (length(d[d$Resp == d$w2_mm,]$RespCode) > 0){d[d$Resp == d$w2_mm,]$RespCode = "w2_mm"}
if (length(d[d$Resp == d$both_mm,]$RespCode) > 0){d[d$Resp == d$both_mm,]$RespCode = "both_mm"}
d$RespCode <- as.factor(d$RespCode)
d <- d[,!names(d)%in% "choices"]
d$Score = ifelse(d$RespCode == "correct", 1,0)
d$W1MM = ifelse(d$RespCode %in% c("correct","w1_mm"), 1,0)
d$W2MM = ifelse(d$RespCode %in% c("correct","w2_mm"), 1,0)
comp = rbind(comp,d)
print(x)
}
comp$delay = as.factor(comp$delay)
return(comp)
}
# test = data from test of immediate memory, used to remove inattentive subjects.
# mem = data from key test trials of subsequent memory
test <- Test_Import("./Data")
mem <- Mem_Import("./Data")
test.subj <- summaryBy(Score ~ Subj , data = test, keep.names = T)
mem = mem[mem$Subj%in% test.subj[test.subj$Score >=0.8,]$Subj,]
summaryBy(Score + W1MM + W2MM ~ cond + delay , data = mem, keep.names = T)
print(paste("Number of excluded subjects = ",length(test.subj[test.subj$Score <=0.8,]$Subj), sep = ""))
# Remove participants who were too close to chance in main task
chance <-summaryBy(Score ~ delay+Subj , data = mem, keep.names = T)
mem <- mem[!mem$Subj %in% chance[chance$Score < 0.3 | chance$Score > 0.95,]$Subj,]
cond_conditional_summary(mem, mem$W1MM,mem$W2MM)
cond_conditional_summary <- function(mem.b, W_Conditional, W_Target){
mem.b$W_Conditional <- W_Conditional
mem.b$W_Target <- W_Target
#  Analysis of W1 by W2 at a group level
by_subj_cond_D <- mem.b %>%
group_by(Subj, cond,delay,W_Conditional) %>%
select(Score, W_Conditional, W_Target, cond,delay,Subj) %>%
summarise(W1_Cond = mean(W_Target, na.rm = TRUE)) %>%
group_by(cond,delay,Subj,W_Conditional) %>%
summarise(W1_Cond_g = mean(W1_Cond, na.rm = TRUE)) %>%
mutate(W1_P_D = W1_Cond_g - lag(W1_Cond_g, default = 0)) %>%
filter(W_Conditional ==1)
by_subj_cond_RPC <- mem.b %>%
group_by(Subj, cond,delay) %>%
select(Score, W_Target, cond,delay,Subj) %>%
summarise(W1_Full = mean(W_Target, na.rm = TRUE)) %>%
group_by(cond,delay, Subj) %>%
summarise(W1_Full_g = mean(W1_Full, na.rm = TRUE)) %>%
full_join(by_subj_cond_D, by = c("cond","delay")) %>%
mutate(W1_RPC = ((2*W1_Full_g)-1)) %>%
mutate(W1_P_D1 = W1_RPC/(W1_RPC +1)) %>%
mutate(D = W1_P_D/W1_P_D1)
by_subj_cond_summary <- by_subj_cond_RPC %>%
group_by(cond,delay,Subj) %>%
select(D,cond,delay,Subj) %>%
summarise(D.mean = mean(D,na.rm=T))
return(by_subj_cond_summary)
}
cond_conditional_summary(mem, mem$W1MM,mem$W2MM)
cond_conditional_summary(mem, mem$W1MM,mem$W2MM)
cond_conditional_summary <- function(mem.b, W_Conditional, W_Target){
mem.b$W_Conditional <- W_Conditional
mem.b$W_Target <- W_Target
#  Analysis of W1 by W2 at a group level
by_subj_cond_D <- mem.b %>%
group_by(Subj, cond,delay,W_Conditional) %>%
select(Score, W_Conditional, W_Target, cond,delay,Subj) %>%
summarise(W1_Cond = mean(W_Target, na.rm = TRUE)) %>%
group_by(cond,delay,Subj,W_Conditional) %>%
summarise(W1_Cond_g = mean(W1_Cond, na.rm = TRUE)) %>%
mutate(W1_P_D = W1_Cond_g - lag(W1_Cond_g, default = 0)) %>%
filter(W_Conditional ==1)
return(by_subj_cond_D)
}
cond_conditional_summary(mem, mem$W1MM,mem$W2MM)
cond_conditional_summary <- function(mem.b, W_Conditional, W_Target){
mem.b$W_Conditional <- W_Conditional
mem.b$W_Target <- W_Target
#  Analysis of W1 by W2 at a group level
by_subj_cond_D <- mem.b %>%
group_by(Subj, cond,delay,W_Conditional) %>%
select(Score, W_Conditional, W_Target, cond,delay,Subj) %>%
summarise(W1_Cond = mean(W_Target, na.rm = TRUE)) %>%
group_by(cond,delay,Subj,W_Conditional) %>%
summarise(W1_Cond_g = mean(W1_Cond, na.rm = TRUE)) %>%
mutate(W1_P_D = W1_Cond_g - lag(W1_Cond_g, default = 0)) %>%
filter(W_Conditional ==1)
by_subj_cond_RPC <- mem.b %>%
group_by(Subj, cond,delay) %>%
select(Score, W_Target, cond,delay,Subj) %>%
summarise(W1_Full = mean(W_Target, na.rm = TRUE)) %>%
group_by(cond,delay, Subj) %>%
summarise(W1_Full_g = mean(W1_Full, na.rm = TRUE)) %>%
full_join(by_subj_cond_D, by = c("cond","delay")) %>%
mutate(W1_RPC = ((2*W1_Full_g)-1)) %>%
mutate(W1_P_D1 = W1_RPC/(W1_RPC +1)) %>%
mutate(D = W1_P_D/W1_P_D1)
return(by_subj_cond_RPC)
}
cond_conditional_summary(mem, mem$W1MM,mem$W2MM)
cond_conditional_summary <- function(mem.b, W_Conditional, W_Target){
mem.b$W_Conditional <- W_Conditional
mem.b$W_Target <- W_Target
#  Analysis of W1 by W2 at a group level
by_subj_cond_D <- mem.b %>%
group_by(Subj, cond,delay,W_Conditional) %>%
select(Score, W_Conditional, W_Target, cond,delay,Subj) %>%
summarise(W1_Cond = mean(W_Target, na.rm = TRUE)) %>%
group_by(cond,delay,Subj,W_Conditional) %>%
summarise(W1_Cond_g = mean(W1_Cond, na.rm = TRUE)) %>%
mutate(W1_P_D = W1_Cond_g - lag(W1_Cond_g, default = 0)) %>%
filter(W_Conditional ==1)
by_subj_cond_RPC <- mem.b %>%
group_by(Subj, cond,delay) %>%
select(Score, W_Target, cond,delay,Subj) %>%
summarise(W1_Full = mean(W_Target, na.rm = TRUE)) %>%
group_by(cond,delay, Subj) %>%
summarise(W1_Full_g = mean(W1_Full, na.rm = TRUE)) %>%
full_join(by_subj_cond_D, by = c("cond","delay","Subj")) %>%
mutate(W1_RPC = ((2*W1_Full_g)-1)) %>%
mutate(W1_P_D1 = W1_RPC/(W1_RPC +1)) %>%
mutate(D = W1_P_D/W1_P_D1)
return(by_subj_cond_RPC)
}
cond_conditional_summary(mem, mem$W1MM,mem$W2MM)
summaryBy(Score + W1MM + W2MM ~ cond + delay , data = subset(mem, Subj == "A1AQK667NBERJ1"), keep.names = T)
summaryBy(Score + W2MM ~ cond + delay + W1MM , data = subset(mem, Subj == "A1AQK667NBERJ1"), keep.names = T)
\
cond_conditional_summary(mem, mem$W1MM,mem$W2MM)
cond_conditional_summary(mem, mem$W1MM,mem$W2MM) -> k
hist(k$D)
cond_conditional_summary <- function(mem.b, W_Conditional, W_Target){
mem.b$W_Conditional <- W_Conditional
mem.b$W_Target <- W_Target
#  Analysis of W1 by W2 at a group level
by_subj_cond_D <- mem.b %>%
group_by(Subj, cond,delay,W_Conditional) %>%
select(Score, W_Conditional, W_Target, cond,delay,Subj) %>%
summarise(W1_Cond = mean(W_Target, na.rm = TRUE)) %>%
group_by(cond,delay,Subj,W_Conditional) %>%
summarise(W1_Cond_g = mean(W1_Cond, na.rm = TRUE)) %>%
mutate(W1_P_D = W1_Cond_g - lag(W1_Cond_g, default = 0)) %>%
filter(W_Conditional ==1)
by_subj_cond_RPC <- mem.b %>%
group_by(Subj, cond,delay) %>%
select(Score, W_Target, cond,delay,Subj) %>%
summarise(W1_Full = mean(W_Target, na.rm = TRUE)) %>%
group_by(cond,delay, Subj) %>%
summarise(W1_Full_g = mean(W1_Full, na.rm = TRUE)) %>%
full_join(by_subj_cond_D, by = c("cond","delay","Subj")) %>%
mutate(W1_RPC = ((2*W1_Full_g)-1)) %>%
mutate(W1_P_D1 = W1_RPC/(W1_RPC +1)) %>%
mutate(D = W1_P_D/W1_P_D1)
by_subj_cond_summary <- by_subj_cond_RPC %>%
group_by(cond,delay,Subj) %>%
select(D,cond,delay,Subj) %>%
summarise(D.mean = mean(D,na.rm=T))
return(by_subj_cond_summary)
}
cond_conditional_summary(mem, mem$W1MM,mem$W2MM)
cond_conditional_summary <- function(mem.b, W_Conditional, W_Target){
mem.b$W_Conditional <- W_Conditional
mem.b$W_Target <- W_Target
#  Analysis of W1 by W2 at a group level
by_subj_cond_D <- mem.b %>%
group_by(Subj, cond,delay,W_Conditional) %>%
select(Score, W_Conditional, W_Target, cond,delay,Subj) %>%
summarise(W1_Cond = mean(W_Target, na.rm = TRUE)) %>%
group_by(cond,delay,Subj,W_Conditional) %>%
summarise(W1_Cond_g = mean(W1_Cond, na.rm = TRUE)) %>%
mutate(W1_P_D = W1_Cond_g - lag(W1_Cond_g, default = 0)) %>%
filter(W_Conditional ==1)
by_subj_cond_RPC <- mem.b %>%
group_by(Subj, cond,delay) %>%
select(Score, W_Target, cond,delay,Subj) %>%
summarise(W1_Full = mean(W_Target, na.rm = TRUE)) %>%
group_by(cond,delay, Subj) %>%
summarise(W1_Full_g = mean(W1_Full, na.rm = TRUE)) %>%
full_join(by_subj_cond_D, by = c("cond","delay","Subj")) %>%
mutate(W1_RPC = ((2*W1_Full_g)-1)) %>%
mutate(W1_P_D1 = W1_RPC/(W1_RPC +1)) %>%
mutate(D = W1_P_D/W1_P_D1)
by_subj_cond_summary <- by_subj_cond_RPC %>%
group_by(cond,delay) %>%
select(D,cond,delay) %>%
summarise(D.mean = mean(D,na.rm=T))
return(by_subj_cond_summary)
}
cond_conditional_summary(mem, mem$W1MM,mem$W2MM)
cond_conditional_summary <- function(mem.b, W_Conditional, W_Target){
mem.b$W_Conditional <- W_Conditional
mem.b$W_Target <- W_Target
#  Analysis of W1 by W2 at a group level
by_subj_cond_D <- mem.b %>%
group_by(Subj, cond,delay,W_Conditional) %>%
select(Score, W_Conditional, W_Target, cond,delay,Subj) %>%
summarise(W1_Cond = mean(W_Target, na.rm = TRUE)) %>%
group_by(cond,delay,W_Conditional) %>%
summarise(W1_Cond_g = mean(W1_Cond, na.rm = TRUE)) %>%
mutate(W1_P_D = W1_Cond_g - lag(W1_Cond_g, default = 0)) %>%
filter(W_Conditional ==1)
by_subj_cond_RPC <- mem.b %>%
group_by(Subj, cond,delay) %>%
select(Score, W_Target, cond,delay,Subj) %>%
summarise(W1_Full = mean(W_Target, na.rm = TRUE)) %>%
group_by(cond,delay) %>%
summarise(W1_Full_g = mean(W1_Full, na.rm = TRUE)) %>%
full_join(by_subj_cond_D, by = c("cond","delay")) %>%
mutate(W1_RPC = ((2*W1_Full_g)-1)) %>%
mutate(W1_P_D1 = W1_RPC/(W1_RPC +1)) %>%
mutate(D = W1_P_D/W1_P_D1)
by_subj_cond_summary <- by_subj_cond_RPC %>%
group_by(cond,delay) %>%
select(D,cond,delay) %>%
summarise(D.mean = mean(D,na.rm=T))
return(by_subj_cond_summary)
}
cond_conditional_summary(mem, mem$W1MM,mem$W2MM)
cond_conditional_summary(mem, mem$W2MM,mem$W1MM)
setwd("~/Dropbox/Studies/MemBinding/Expt 3 - BtwnSubjCond")
cond_conditional_summary <- function(mem.b, W_Conditional, W_Target){
mem.b$W_Conditional <- W_Conditional
mem.b$W_Target <- W_Target
#  Analysis of W1 by W2 at a group level
by_subj_cond_D <- mem.b %>%
group_by(cond,delay,W_Conditional) %>%
select(Score, W_Conditional, W_Target, cond,delay) %>%
summarise(W1_Cond = mean(W_Target, na.rm = TRUE)) %>%
group_by(cond,delay,W_Conditional) %>%
summarise(W1_Cond_g = mean(W1_Cond, na.rm = TRUE)) %>%
mutate(W1_P_D = W1_Cond_g - lag(W1_Cond_g, default = 0)) %>%
filter(W_Conditional ==1)
by_subj_cond_RPC <- mem.b %>%
group_by(cond,delay) %>%
select(Score, W_Target, cond,delay) %>%
summarise(W1_Full = mean(W_Target, na.rm = TRUE)) %>%
group_by(cond,delay) %>%
summarise(W1_Full_g = mean(W1_Full, na.rm = TRUE)) %>%
full_join(by_subj_cond_D, by = c("cond","delay")) %>%
mutate(W1_RPC = ((2*W1_Full_g)-1)) %>%
mutate(W1_P_D1 = W1_RPC/(W1_RPC +1)) %>%
mutate(D = W1_P_D/W1_P_D1)
by_subj_cond_summary <- by_subj_cond_RPC %>%
group_by(cond,delay) %>%
select(D,cond,delay) %>%
summarise(D.mean = mean(D,na.rm=T))
return(by_subj_cond_summary)
}
cond_mem_boot <- function(mem, W_Conditional, W_Target, iter, alpha){
mem$W_Conditional <- W_Conditional
mem$W_Target <- W_Target
orig_data <- cond_conditional_summary(mem, mem$W_Conditional, mem$W_Target)
orig_summary <- orig_data
orig_data$iter = 0
for (i in 1:iter){
subj.sample1 <- sample(unique(subset(mem, cond =="comp")$Subj), replace = T)
subj.sample2 <- sample(unique(subset(mem, cond =="assoc")$Subj), replace = T)
subj.sample <- c(subj.sample1, subj.sample2)
mem.b <- subset(mem, Subj == subj.sample[1])
for (j in 2:length(subj.sample)){
mem.subj <- subset(mem, Subj == subj.sample[j])
mem.subj$Subj <- paste(subj.sample[j],j,sep = ".")
mem.b <- rbind(mem.b,mem.subj)
}
by_subj_cond_summary <- cond_conditional_summary(mem.b, mem.b$W_Conditional, mem.b$W_Target)
by_subj_cond_summary$iter = i
orig_data <- rbind(orig_data,by_subj_cond_summary)
}
data_diff <- orig_data  %>% mutate(D_Diff = D.mean - lag(D.mean, default = 0)) %>% filter(delay == "6") %>% group_by(cond) %>% summarize(low=quantile(D_Diff, alpha / 2), high=quantile(D_Diff, 1 - alpha / 2))
orig_data <- orig_data %>% group_by(cond,delay) %>% summarize(low=quantile(D.mean, alpha / 2),
high=quantile(D.mean, 1 - alpha / 2))
orig_summary <- full_join(orig_summary,orig_data, by = c("cond","delay"))
orig_summary$diff <- c(filter(data_diff,cond == "assoc")$low,filter(data_diff,cond == "assoc")$high,filter(data_diff,cond == "comp")$low,filter(data_diff,cond == "comp")$high)
return(orig_summary)
}
library(ez)
library(jsonlite)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(doBy)
## for bootstrapping 95% confidence intervals -- from Mike Frank https://github.com/langcog/KTE/blob/master/mcf.useful.R
library(bootstrap)
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)} #  mean(x,na.rm=na.rm) -
ci.high <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) } #- mean(x,na.rm=na.rm)}
Test_Import = function(path_name){
library(jsonlite)
list.files(path = path_name,full.names = T, pattern = ".txt") -> file_list
comp = c()
for (x in file_list){
file_name = x
df <- fromJSON(file_name)
d <- df$data[4]$trialdata[df$data[4]$trialdata$Screen == "judge",]
d <- d[ grep("categorize",d$trial_type, ignore.case = TRUE),]
d <- d[,!names(d)%in% "choices"]
d$Score = ifelse(d$key_press == d$corr_key, 1,0)
comp = rbind(comp,d)
print(x)
}
return(comp)
}
Mem_Import = function(path_name){
library(jsonlite)
list.files(path = path_name,full.names = T, pattern = ".txt") -> file_list
comp = c()
for (x in file_list){
file_name = x
df <- fromJSON(file_name)
d <- df$data[4]$trialdata[df$data[4]$trialdata$Screen == "probe",]
d <- d[ grep("button-response",d$trial_type, ignore.case = TRUE),]
d$Resp = NA
for (i in 1:length(d$Resp)){
choice = d$button_pressed[i] + 1
d$Resp[i] = d$choices[[i]][choice]
}
d$Resp <- as.factor(d$Resp)
d$RespCode = NA
if (length(d[d$Resp == d$correct,]$RespCode) > 0){d[d$Resp == d$correct,]$RespCode = "correct"}
if (length(d[d$Resp == d$w1_mm,]$RespCode) > 0){d[d$Resp == d$w1_mm,]$RespCode = "w1_mm"}
if (length(d[d$Resp == d$w2_mm,]$RespCode) > 0){d[d$Resp == d$w2_mm,]$RespCode = "w2_mm"}
if (length(d[d$Resp == d$both_mm,]$RespCode) > 0){d[d$Resp == d$both_mm,]$RespCode = "both_mm"}
d$RespCode <- as.factor(d$RespCode)
d <- d[,!names(d)%in% "choices"]
d$Score = ifelse(d$RespCode == "correct", 1,0)
d$W1MM = ifelse(d$RespCode %in% c("correct","w1_mm"), 1,0)
d$W2MM = ifelse(d$RespCode %in% c("correct","w2_mm"), 1,0)
comp = rbind(comp,d)
print(x)
}
comp$delay = as.factor(comp$delay)
return(comp)
}
# test = data from test of immediate memory, used to remove inattentive subjects.
# mem = data from key test trials of subsequent memory
test <- Test_Import("./Data")
mem <- Mem_Import("./Data")
test.subj <- summaryBy(Score ~ Subj , data = test, keep.names = T)
mem = mem[mem$Subj%in% test.subj[test.subj$Score >=0.8,]$Subj,]
summaryBy(Score + W1MM + W2MM ~ cond + delay , data = mem, keep.names = T)
print(paste("Number of excluded subjects = ",length(test.subj[test.subj$Score <=0.8,]$Subj), sep = ""))
# Remove participants who were too close to chance in main task
chance <-summaryBy(Score ~ delay+Subj , data = mem, keep.names = T)
mem <- mem[!mem$Subj %in% chance[chance$Score < 0.3 | chance$Score > 0.95,]$Subj,]
w2_cond_p <- mem %>%
group_by(Subj, delay,cond,W1MM) %>%
select(Score, W2MM, W1MM,delay, cond,Subj) %>%
summarise(W2MM = mean(W2MM, na.rm = TRUE)) %>%
mutate(W2MM_D = W2MM - lag(W2MM, default = 0)) %>%
filter(W1MM ==1)
w2_cond_p %>%
group_by(cond,delay) %>%
select(W2MM_D,delay, cond) %>%
summarise(W2MM_D.mean = mean(W2MM_D, na.rm = TRUE), W2MM_D.se = sd(W2MM_D,na.rm=TRUE)/sqrt(length(unique(mem$Subj))))
ezANOVA(data.frame(w2_cond_p), W2MM_D, wid = .(Subj), within = .(delay), between = .(cond))
w1_cond_p <- mem %>%
group_by(Subj, delay,cond,W2MM) %>%
select(Score, W2MM, W1MM, delay,cond,Subj) %>%
summarise(W1MM = mean(W1MM, na.rm = TRUE)) %>%
mutate(W1MM_D = W1MM - lag(W1MM, default = 0)) %>%
filter(W2MM ==1)
w1_cond_p %>%
group_by(cond,delay) %>%
select(W1MM_D,delay, cond) %>%
summarise(W1MM_D.mean = mean(W1MM_D, na.rm = TRUE), W1MM_D.se = sd(W1MM_D,na.rm=TRUE)/sqrt(length(unique(mem$Subj))))
ezANOVA(data.frame(w1_cond_p), W1MM_D, wid = .(Subj), within = .(delay), between = .(cond))
W2_on_W1_cond <- cond_mem_boot(mem, mem$W1MM, mem$W2MM, 100, 0.05)
print(W2_on_W1_cond)
W1_on_W2_cond <- cond_mem_boot(mem, mem$W2MM, mem$W1MM, 100, 0.05)
print(W1_on_W2_cond)
sample(c(1,2,3),replace = T)
sample(c(1,2,3),replace = T)
sample(c(1,2,3),replace = T)
sample(c(1,2,3),replace = T)
setwd("~/GitHub/iPad_TurnTaking/DistrAnalyses/STAN_Analysis")
model <- read.csv("fixEf_Transf3_output.csv", header = T)
model.graph = data.frame(Age = rep(rep(c("Adult","5-yr-old","3-yr-old"), each = 4), times = 3),
AnswerType = rep(rep(c("Predictable","Unpredictable"), each = 2),times = 9),
SceneType = rep(c("Match","Mismatch"), times = 18),
Parameter = rep(c("Mu", "Sigma","Tau"), each = 12))
model.graph$Value = NA
model.graph[model.graph$Parameter == "Mu" & model.graph$Age == "Adult" & model.graph$AnswerType == "Predictable" &
model.graph$SceneType == "Match",]$Value <- subset(model, X == "beta[1]")$mean
model.graph[model.graph$Parameter == "Mu" & model.graph$Age == "Adult" & model.graph$AnswerType == "Predictable" &
model.graph$SceneType == "Mismatch",]$Value <- (subset(model, X == "beta[1]")$mean + subset(model, X == "beta[2]")$mean)
model.graph[model.graph$Parameter == "Mu" & model.graph$Age == "Adult" & model.graph$AnswerType == "Unpredictable" &
model.graph$SceneType == "Match",]$Value <- (subset(model, X == "beta[1]")$mean + subset(model, X == "beta[3]")$mean)
model.graph[model.graph$Parameter == "Mu" & model.graph$Age == "Adult" & model.graph$AnswerType == "Unpredictable" &
model.graph$SceneType == "Mismatch",]$Value <- (subset(model, X == "beta[1]")$mean + subset(model, X == "beta[2]")$mean + subset(model, X == "beta[3]")$mean + subset(model, X == "beta[6]")$mean)
model.graph[model.graph$Parameter == "Mu" & model.graph$Age == "5-yr-old" & model.graph$AnswerType == "Predictable" &
model.graph$SceneType == "Match",]$Value <- (subset(model, X == "beta[1]")$mean + subset(model, X == "beta[4]")$mean)
model.graph[model.graph$Parameter == "Mu" & model.graph$Age == "5-yr-old" & model.graph$AnswerType == "Predictable" &
model.graph$SceneType == "Mismatch",]$Value <- (subset(model, X == "beta[1]")$mean + subset(model, X == "beta[4]")$mean + subset(model, X == "beta[2]")$mean  + subset(model, X == "beta[7]")$mean)
model.graph[model.graph$Parameter == "Mu" & model.graph$Age == "5-yr-old" & model.graph$AnswerType == "Unpredictable" &
model.graph$SceneType == "Match",]$Value <- (subset(model, X == "beta[1]")$mean + subset(model, X == "beta[4]")$mean + subset(model, X == "beta[3]")$mean+ subset(model, X == "beta[9]")$mean)
model.graph[model.graph$Parameter == "Mu" & model.graph$Age == "5-yr-old" & model.graph$AnswerType == "Unpredictable" &
model.graph$SceneType == "Mismatch",]$Value <- (subset(model, X == "beta[1]")$mean + subset(model, X == "beta[2]")$mean+ subset(model, X == "beta[4]")$mean  + subset(model, X == "beta[3]")$mean + subset(model, X == "beta[6]")$mean+ subset(model, X == "beta[7]")$mean+ subset(model, X == "beta[9]")$mean   + subset(model, X == "beta[11]")$mean)
model.graph[model.graph$Parameter == "Mu" & model.graph$Age == "3-yr-old" & model.graph$AnswerType == "Predictable" &
model.graph$SceneType == "Match",]$Value <- (subset(model, X == "beta[1]")$mean + subset(model, X == "beta[5]")$mean)
model.graph[model.graph$Parameter == "Mu" & model.graph$Age == "3-yr-old" & model.graph$AnswerType == "Predictable" &
model.graph$SceneType == "Mismatch",]$Value <- (subset(model, X == "beta[1]")$mean + subset(model, X == "beta[5]")$mean + subset(model, X == "beta[2]")$mean  + subset(model, X == "beta[8]")$mean)
model.graph[model.graph$Parameter == "Mu" & model.graph$Age == "3-yr-old" & model.graph$AnswerType == "Unpredictable" &
model.graph$SceneType == "Match",]$Value <- (subset(model, X == "beta[1]")$mean + subset(model, X == "beta[5]")$mean + subset(model, X == "beta[3]")$mean+ subset(model, X == "beta[10]")$mean)
model.graph[model.graph$Parameter == "Mu" & model.graph$Age == "3-yr-old" & model.graph$AnswerType == "Unpredictable" &
model.graph$SceneType == "Mismatch",]$Value <- (subset(model, X == "beta[1]")$mean + subset(model, X == "beta[2]")$mean+ subset(model, X == "beta[5]")$mean  + subset(model, X == "beta[3]")$mean + subset(model, X == "beta[6]")$mean+ subset(model, X == "beta[8]")$mean+ subset(model, X == "beta[10]")$mean   + subset(model, X == "beta[12]")$mean)
######## Sigma
model.graph[model.graph$Parameter == "Sigma" & model.graph$Age == "Adult" & model.graph$AnswerType == "Predictable" &
model.graph$SceneType == "Match",]$Value <- subset(model, X == "beta_s[1]")$mean
model.graph[model.graph$Parameter == "Sigma" & model.graph$Age == "Adult" & model.graph$AnswerType == "Predictable" &
model.graph$SceneType == "Mismatch",]$Value <- (subset(model, X == "beta_s[1]")$mean + subset(model, X == "beta_s[2]")$mean)
model.graph[model.graph$Parameter == "Sigma" & model.graph$Age == "Adult" & model.graph$AnswerType == "Unpredictable" &
model.graph$SceneType == "Match",]$Value <- (subset(model, X == "beta_s[1]")$mean + subset(model, X == "beta_s[3]")$mean)
model.graph[model.graph$Parameter == "Sigma" & model.graph$Age == "Adult" & model.graph$AnswerType == "Unpredictable" &
model.graph$SceneType == "Mismatch",]$Value <- (subset(model, X == "beta_s[1]")$mean + subset(model, X == "beta_s[2]")$mean + subset(model, X == "beta_s[3]")$mean + subset(model, X == "beta_s[6]")$mean)
model.graph[model.graph$Parameter == "Sigma" & model.graph$Age == "5-yr-old" & model.graph$AnswerType == "Predictable" &
model.graph$SceneType == "Match",]$Value <- (subset(model, X == "beta_s[1]")$mean + subset(model, X == "beta_s[4]")$mean)
model.graph[model.graph$Parameter == "Sigma" & model.graph$Age == "5-yr-old" & model.graph$AnswerType == "Predictable" &
model.graph$SceneType == "Mismatch",]$Value <- (subset(model, X == "beta_s[1]")$mean + subset(model, X == "beta_s[4]")$mean + subset(model, X == "beta_s[2]")$mean  + subset(model, X == "beta_s[7]")$mean)
model.graph[model.graph$Parameter == "Sigma" & model.graph$Age == "5-yr-old" & model.graph$AnswerType == "Unpredictable" &
model.graph$SceneType == "Match",]$Value <- (subset(model, X == "beta_s[1]")$mean + subset(model, X == "beta_s[4]")$mean + subset(model, X == "beta_s[3]")$mean+ subset(model, X == "beta_s[9]")$mean)
model.graph[model.graph$Parameter == "Sigma" & model.graph$Age == "5-yr-old" & model.graph$AnswerType == "Unpredictable" &
model.graph$SceneType == "Mismatch",]$Value <- (subset(model, X == "beta_s[1]")$mean + subset(model, X == "beta_s[2]")$mean+ subset(model, X == "beta_s[4]")$mean  + subset(model, X == "beta_s[3]")$mean + subset(model, X == "beta_s[6]")$mean+ subset(model, X == "beta_s[7]")$mean+ subset(model, X == "beta_s[9]")$mean   + subset(model, X == "beta_s[11]")$mean)
model.graph[model.graph$Parameter == "Sigma" & model.graph$Age == "3-yr-old" & model.graph$AnswerType == "Predictable" &
model.graph$SceneType == "Match",]$Value <- (subset(model, X == "beta_s[1]")$mean + subset(model, X == "beta_s[5]")$mean)
model.graph[model.graph$Parameter == "Sigma" & model.graph$Age == "3-yr-old" & model.graph$AnswerType == "Predictable" &
model.graph$SceneType == "Mismatch",]$Value <- (subset(model, X == "beta_s[1]")$mean + subset(model, X == "beta_s[5]")$mean + subset(model, X == "beta_s[2]")$mean  + subset(model, X == "beta_s[8]")$mean)
model.graph[model.graph$Parameter == "Sigma" & model.graph$Age == "3-yr-old" & model.graph$AnswerType == "Unpredictable" &
model.graph$SceneType == "Match",]$Value <- (subset(model, X == "beta_s[1]")$mean + subset(model, X == "beta_s[5]")$mean + subset(model, X == "beta_s[3]")$mean+ subset(model, X == "beta_s[10]")$mean)
model.graph[model.graph$Parameter == "Sigma" & model.graph$Age == "3-yr-old" & model.graph$AnswerType == "Unpredictable" &
model.graph$SceneType == "Mismatch",]$Value <- (subset(model, X == "beta_s[1]")$mean + subset(model, X == "beta_s[2]")$mean+ subset(model, X == "beta_s[5]")$mean  + subset(model, X == "beta_s[3]")$mean + subset(model, X == "beta_s[6]")$mean+ subset(model, X == "beta_s[8]")$mean+ subset(model, X == "beta_s[10]")$mean   + subset(model, X == "beta_s[12]")$mean)
######## Tau
model.graph[model.graph$Parameter == "Tau" & model.graph$Age == "Adult" & model.graph$AnswerType == "Predictable" &
model.graph$SceneType == "Match",]$Value <- subset(model, X == "beta_t[1]")$mean
model.graph[model.graph$Parameter == "Tau" & model.graph$Age == "Adult" & model.graph$AnswerType == "Predictable" &
model.graph$SceneType == "Mismatch",]$Value <- (subset(model, X == "beta_t[1]")$mean + subset(model, X == "beta_t[2]")$mean)
model.graph[model.graph$Parameter == "Tau" & model.graph$Age == "Adult" & model.graph$AnswerType == "Unpredictable" &
model.graph$SceneType == "Match",]$Value <- (subset(model, X == "beta_t[1]")$mean + subset(model, X == "beta_t[3]")$mean)
model.graph[model.graph$Parameter == "Tau" & model.graph$Age == "Adult" & model.graph$AnswerType == "Unpredictable" &
model.graph$SceneType == "Mismatch",]$Value <- (subset(model, X == "beta_t[1]")$mean + subset(model, X == "beta_t[2]")$mean + subset(model, X == "beta_t[3]")$mean + subset(model, X == "beta_t[6]")$mean)
model.graph[model.graph$Parameter == "Tau" & model.graph$Age == "5-yr-old" & model.graph$AnswerType == "Predictable" &
model.graph$SceneType == "Match",]$Value <- (subset(model, X == "beta_t[1]")$mean + subset(model, X == "beta_t[4]")$mean)
model.graph[model.graph$Parameter == "Tau" & model.graph$Age == "5-yr-old" & model.graph$AnswerType == "Predictable" &
model.graph$SceneType == "Mismatch",]$Value <- (subset(model, X == "beta_t[1]")$mean + subset(model, X == "beta_t[4]")$mean + subset(model, X == "beta_t[2]")$mean  + subset(model, X == "beta_t[7]")$mean)
model.graph[model.graph$Parameter == "Tau" & model.graph$Age == "5-yr-old" & model.graph$AnswerType == "Unpredictable" &
model.graph$SceneType == "Match",]$Value <- (subset(model, X == "beta_t[1]")$mean + subset(model, X == "beta_t[4]")$mean + subset(model, X == "beta_t[3]")$mean+ subset(model, X == "beta_t[9]")$mean)
model.graph[model.graph$Parameter == "Tau" & model.graph$Age == "5-yr-old" & model.graph$AnswerType == "Unpredictable" &
model.graph$SceneType == "Mismatch",]$Value <- (subset(model, X == "beta_t[1]")$mean + subset(model, X == "beta_t[2]")$mean+ subset(model, X == "beta_t[4]")$mean  + subset(model, X == "beta_t[3]")$mean + subset(model, X == "beta_t[6]")$mean+ subset(model, X == "beta_t[7]")$mean+ subset(model, X == "beta_t[9]")$mean   + subset(model, X == "beta_t[11]")$mean)
model.graph[model.graph$Parameter == "Tau" & model.graph$Age == "3-yr-old" & model.graph$AnswerType == "Predictable" &
model.graph$SceneType == "Match",]$Value <- (subset(model, X == "beta_t[1]")$mean + subset(model, X == "beta_t[5]")$mean)
model.graph[model.graph$Parameter == "Tau" & model.graph$Age == "3-yr-old" & model.graph$AnswerType == "Predictable" &
model.graph$SceneType == "Mismatch",]$Value <- (subset(model, X == "beta_t[1]")$mean + subset(model, X == "beta_t[5]")$mean + subset(model, X == "beta_t[2]")$mean  + subset(model, X == "beta_t[8]")$mean)
model.graph[model.graph$Parameter == "Tau" & model.graph$Age == "3-yr-old" & model.graph$AnswerType == "Unpredictable" &
model.graph$SceneType == "Match",]$Value <- (subset(model, X == "beta_t[1]")$mean + subset(model, X == "beta_t[5]")$mean + subset(model, X == "beta_t[3]")$mean+ subset(model, X == "beta_t[10]")$mean)
model.graph[model.graph$Parameter == "Tau" & model.graph$Age == "3-yr-old" & model.graph$AnswerType == "Unpredictable" &
model.graph$SceneType == "Mismatch",]$Value <- (subset(model, X == "beta_t[1]")$mean + subset(model, X == "beta_t[2]")$mean+ subset(model, X == "beta_t[5]")$mean  + subset(model, X == "beta_t[3]")$mean + subset(model, X == "beta_t[6]")$mean+ subset(model, X == "beta_t[8]")$mean+ subset(model, X == "beta_t[10]")$mean   + subset(model, X == "beta_t[12]")$mean)
# Subtract constant to get real Values
model.graph[model.graph$Parameter == "Mu",]$Value <- model.graph[model.graph$Parameter == "Mu",]$Value - 725
model.graph$Age <- ordered(model.graph$Age, levels = c("Adult","5-yr-old","3-yr-old"))
ggplot(data = model.graph, aes(x = AnswerType, y = Value)) +
geom_bar(stat = "identity", position = "dodge", aes(fill = SceneType)) +
facet_wrap(~Parameter+Age)
>>>>>>> Stashed changes
