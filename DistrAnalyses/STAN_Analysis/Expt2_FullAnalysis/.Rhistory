First, the overall distribution of looking times.
```{r}
qplot(looking_time, fill = lab, facets = ~ lab, binwidth = 2, data = d)
```
Stanford has a large number of 2s looking times because that's the lookaway from the tracker. So when a child isn't looking at all, they get a 2s. *How should we deal with this?*
Next, are children making it through the experiment? Looks like essentially everyone does.
```{r}
final_trial <- d %>%
group_by(lab, subid) %>%
summarize(max_trial = max(trial_num[looking_time > 2]))
qplot(max_trial, fill = lab, data = final_trial)
```
Now, histogram of looking time by trial number. Looks like looking times are staying pretty long.
```{r}
ggplot(d, aes(x = looking_time, fill = lab)) +
geom_histogram(binwidth = 2) +
facet_wrap(~trial_num)
```
We can look at this by age, too.
```{r}
qplot(age_days, looking_time, col = lab, facets = ~ trial_num, data = d) +
geom_smooth(aes(group = 1), method = "lm", col = "black")
```
Plot means.
```{r}
ms <- d %>%
group_by(lab, trial_num) %>%
multi_boot_standard(col = "looking_time", na.rm=TRUE)
ggplot(ms, aes(x = trial_num, y = mean, col = lab)) +
geom_line() +
geom_linerange(aes(ymin = ci_lower, ymax = ci_upper),
position = position_dodge(width = .1))
```
## Condition differences
### Between-subjects analysis
Doesn't compute difference scores - treats IDS and ADS observations as independent. These analyses should likely be lower-powered. (Interested to hear people's thoughts as to whether they should be included).
```{r}
ms <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
group_by(trial_num, trial_type) %>%
multi_boot_standard(col = "looking_time", na.rm=TRUE)
ggplot(ms, aes(x = trial_num, y = mean, col = trial_type)) +
geom_line() +
geom_linerange(aes(ymin = ci_lower, ymax = ci_upper),
position = position_dodge(width= .1)) +
ylab("Looking time (s)")
```
Split by lab (which is really age now).
```{r}
ms <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
group_by(lab, trial_num, trial_type) %>%
multi_boot_standard(col = "looking_time", na.rm=TRUE) %>%
ungroup %>%
mutate(lab = fct_relevel(lab, "ubc"))
ggplot(ms, aes(x = trial_num, y = mean, col = trial_type)) +
geom_smooth(se = FALSE, span = 2) +
facet_wrap(~lab) +
geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper),
position = position_dodge(width= .1))+
ylab("Looking time (s)") +
scale_color_solarized(name = "Trial Type") +
theme(legend.position = "bottom")
```
Take a look at this in log space as well, following Csibra et al. (2015), "Statistical Treatment of Looking-Time Data." Doesn't change much, but is likely better.
```{r}
ms <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
group_by(lab, trial_num, trial_type) %>%
mutate(log10_looking_time = log10(looking_time)) %>%
multi_boot_standard(col = "log10_looking_time", na.rm=TRUE)
ggplot(ms, aes(x = trial_num, y = mean, col = trial_type)) +
geom_smooth(se = FALSE, span = 2) +
facet_wrap(~lab) +
geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper),
position = position_dodge(width= .1)) +
ylab("Log looking time (s)") +
scale_color_solarized(name = "Trial Type") +
theme(legend.position = "bottom")
```
### Within-subjects
Now do (perhaps) the more appropriate analysis: For each pair of trials, subtract to get the difference score. Again following Csibra, we do a difference of logs.
```{r}
diffs <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
group_by(lab, subid, age_days, trial_num) %>%
filter(n() == 2) %>% # take only pairs that are complete
summarise(idspref = log10(looking_time[trial_type=="IDS"]) -
log10(looking_time[trial_type=="ADS"]))
```
What's the distributional form of these data?
```{r}
qplot(idspref, data = diffs)
```
How do they change with trials?
```{r}
ms_diff <- diffs %>%
group_by(lab, trial_num) %>%
multi_boot_standard(col = "idspref", na.rm=TRUE)
ggplot(ms_diff, aes(x = trial_num, y = mean)) +
geom_smooth(se = FALSE, span = 2) +
facet_wrap(~lab) +
geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper),
position = position_dodge(width= .1)) +
ylab("IDS preference (log10 s)") +
geom_hline(yintercept = 0, lty = 2)
```
Or with age?
```{r}
qplot(age_days, idspref, col = lab, group = 1, data = diffs) +
geom_smooth(method = "lm") +
geom_hline(yintercept = 0, lty = 2) +
ylab("IDS preference (s)")
```
By age and by trial.
```{r}
qplot(age_days, idspref, col = lab, group = 1, data = diffs) +
geom_smooth(method = "lm") +
facet_wrap(~trial_num) +
geom_hline(yintercept = 0, lty = 2) +
ylab("IDS preference (s)")
```
## Hypothesis tests
### One Sample t-test against chance
Using log transformed looking time.
```{r}
d_t_test1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time)) %>%
group_by(subid,trial_type) %>%
summarise(log_lt = mean(log_lt)) %>%
group_by(subid) %>%
filter(n() == 2) %>%
summarize(log_lt_diff = log_lt[trial_type == "IDS"] - log_lt[trial_type == "ADS"])
t.test(d_t_test1$log_lt_diff , mu = 0)
```
### Paired t-test
As above, but perhaps it is simpler to compare conditions, as our mixed effects models will use a condition predictor. Using log transformed looking time.
```{r}
d_t_test2 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time)) %>%
group_by(subid,trial_type) %>%
summarise(log_lt = mean(log_lt))
t.test(log_lt ~  trial_type, data = d_t_test2, paired = T)
```
### IDS Preference across age
#### Linear effect of age
Planned regression: 1 + CentredAge * Trial Type + (1 + Centred Age * Trial Type)\\
For some crazy reason this model won't converge in r markdown, but does converge in the console (??!), so I removed the by lab interaction
```{r}
d_lmer1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time), AgeC = (age_days - mean(age_days))/sd(age_days))
summary(lmer(log_lt ~ 1 + AgeC * trial_type + (1+ AgeC + trial_type|lab), data = d_lmer1))
```
#### Quadratic effect of age
Planned regression: 1 + (CentredAge + CentredAge^2) * Trial Type + (1 + (Centred Age + CentredAge ^2) * Trial Type)\\
I removed the by lab interaction to aid convergence
```{r}
d_lmer2 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time), AgeC = (age_days - mean(age_days))/sd(age_days))
summary(lmer(log_lt ~ 1 + poly(AgeC,2) * trial_type + (1+ poly(AgeC,2) + trial_type|lab), data = d_lmer2))
```
#### Secondary hypothesis tests, e.g trial order and age.
We will fit a linear mixed effects model predicting all individual observations, with the structure:\\
log(looking.time) ~ trial.num * stimulus * age + (trial.num * stimulus | subid) + (trial.num * stimulus * age | lab)\\
NB. This is taken from the RRR. Does stimulus here refer to condition or item? I have taken it to refer to condition.\\
Interactions removed to aid convergence.
```{r}
d_lmer3 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time), AgeC = (age_days - mean(age_days))/sd(age_days),trial_numC = (trial_num - mean(trial_num))/sd(trial_num))
summary(lmer(log_lt ~ 1 + AgeC * trial_type * trial_numC + (1+ trial_type + trial_numC|subid)+ (1+ AgeC + trial_type + trial_numC|lab) , data = d_lmer3))
```
# Conclusions
Practical recommendations:
- Need to make standardized templates for `lab`, `subject`, and `trial` data.
- Need to develop policies for data exclusion at the subject level (e.g., any child excluded)
- Need to walk through and select the planned analyses - this is going to be tricky!
Conclusions: It looks like we're seeing some IDS preference for each group, albeit at a different part of the experiment for each age/lab combo.
options(dplyr.width = Inf)
knitr::opts_chunk$set(message = FALSE, warning = FALSE, cache=TRUE)
library(lme4)
library(tidyverse)
library(eyetrackingR)
library(stringr)
library(lubridate)
library(bit64) # necessary because of times from SMI > max integer size
library(langcog)
library(knitr)
library(forcats)
source("et_helper.R")
theme_set(theme_bw())
raw_data_path <- "pilot/frank/"
info_path <- "info/"
processed_data_path <- "processed_data/frank/"
all_data <- dir(raw_data_path, pattern="*.txt") %>%
paste0(raw_data_path, .) %>%
map_df(get_smi_header) %>%
split(.$file_name) %>%
map_df(read_smi_idf) %>%
split(.$file_name) %>%
map_df(preprocess_data)
frank_data <- all_data %>%
group_by(file_name, trial, stimulus) %>%
summarise(looking_time = max(t_stim)) %>%
mutate(trial_cat = ifelse(str_detect(stimulus, ".jpg"), "speech","other")) %>%
filter(trial_cat == "speech") %>%
group_by(file_name) %>%
filter(trial > 5) %>%
mutate(trial_num = 1:n(),
subid = str_replace(str_replace(file_name,raw_data_path,""),
".txt",""))
info <- read_csv("info/frank_demo.csv")
frank_data <- info %>%
select(subid, age, order) %>%
left_join(frank_data)
orders <- read_csv("info/orders.csv") %>%
gather(marker, stimulus, 2:19) %>%
rename(order = Order) %>%
filter(!str_detect(stimulus, "Train")) %>%
group_by(order) %>%
mutate(trial_num = 1:n()) %>%
separate(stimulus, into = c("trial_type", "stim_num"), sep = -2) %>%
select(-marker, -stim_num)
frank_data <- left_join(frank_data, orders) %>%
mutate(trial_num = ceiling(trial_num  / 2)) %>%
mutate(age_days = as.numeric(age),
lab = "stanford",
method = "eye-tracking") %>%
select(lab, method, subid, age_days, trial_type, trial_num, looking_time)
floccia_data <- read_csv("pilot/floccia/pilot data.csv") %>%
rename(age_days = age,
looking_time = LT) %>%
mutate(subid = as.character(id),
method = "HPP",
stimulus = str_replace(str_replace(stimulus, ".wav", ""),
"Manybabies\\\\", "")) %>%
separate(stimulus, into = c("trial_type", "stim_num"), sep = "-") %>%
mutate(trial_num = ceiling(trial/2)) %>%
select(lab, method, subid, age_days, trial_type, trial_num, looking_time)
hamlin_path <- "pilot/hamlin/"
hamlin_data <- dir(hamlin_path, pattern="*.csv") %>%
paste0(hamlin_path, .) %>%
map_df(function(x) {read_csv(x) %>% mutate(order = x)}) %>%
mutate(order = as.numeric(str_replace(str_replace(order, ".csv",""),
"pilot/hamlin/order",""))) %>%
gather(trial, looking_time,
starts_with("Train"), starts_with("IDS"), starts_with("ADS")) %>%
separate(trial, into = c("trial_type","trial_num"), sep = -2) %>%
mutate(lab = "ubc",
method = "single-screen",
trial_num = as.numeric(trial_num),
age_days = str_split(age, ";") %>%
map_dbl(function(x) as.numeric(x[1]) * 30.3 + as.numeric(x[2]))) %>%
rename(subid = subnum) %>%
select(lab, method, subid, age_days, trial_type, trial_num, looking_time)
d <- bind_rows(floccia_data, hamlin_data, frank_data)
kable(head(d))
d_t_test1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time)) %>%
group_by(subid,trial_type) %>%
summarise(log_lt = mean(log_lt)) %>%
group_by(subid) %>%
filter(n() == 2) %>%
summarize(log_lt_diff = log_lt[trial_type == "IDS"] - log_lt[trial_type == "ADS"])
t.test(d_t_test1$log_lt_diff , mu = 0)
d_lmer1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time), AgeC = (age_days - mean(age_days))/sd(age_days))
summary(lmer(log_lt ~ 1 + AgeC * trial_type + (1+ AgeC + trial_type|lab), data = d_lmer1))
d_lmer1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time), AgeC = (age_days - mean(age_days))/sd(age_days))
summary(lmer(log_lt ~ 1 + AgeC * trial_type + (1+ AgeC * trial_type|lab), data = d_lmer1))
orders <- read_csv("info/orders.csv") %>%
gather(marker, stimulus, 2:19) %>%
rename(order = Order) %>%
filter(!str_detect(stimulus, "Train")) %>%
group_by(order) %>%
mutate(trial_num = 1:n()) %>%
separate(stimulus, into = c("trial_type", "stim_num"), sep = -2) %>%
select(-marker, -stim_num)
frank_data <- left_join(frank_data, orders) %>%
mutate(trial_num = ceiling(trial_num  / 2)) %>%
mutate(age_days = as.numeric(age),
lab = "stanford",
method = "eye-tracking") %>%
select(lab, method, subid, age_days, trial_type, trial_num, looking_time)
info <- read_csv("info/frank_demo.csv")
frank_data <- info %>%
select(subid, age, order) %>%
left_join(frank_data)
frank_data <- all_data %>%
group_by(file_name, trial, stimulus) %>%
summarise(looking_time = max(t_stim)) %>%
mutate(trial_cat = ifelse(str_detect(stimulus, ".jpg"), "speech","other")) %>%
filter(trial_cat == "speech") %>%
group_by(file_name) %>%
filter(trial > 5) %>%
mutate(trial_num = 1:n(),
subid = str_replace(str_replace(file_name,raw_data_path,""),
".txt",""))
orders <- read_csv("info/orders.csv") %>%
gather(marker, stimulus, 2:19) %>%
rename(order = Order) %>%
filter(!str_detect(stimulus, "Train")) %>%
group_by(order) %>%
mutate(trial_num = 1:n()) %>%
separate(stimulus, into = c("trial_type", "stim_num"), sep = -2) %>%
select(-marker, -stim_num)
frank_data <- left_join(frank_data, orders) %>%
mutate(trial_num = ceiling(trial_num  / 2)) %>%
mutate(age_days = as.numeric(age),
lab = "stanford",
method = "eye-tracking") %>%
select(lab, method, subid, age_days, trial_type, trial_num, looking_time)
orders
frank_data
frank_data <- all_data %>%
group_by(file_name, trial, stimulus) %>%
summarise(looking_time = max(t_stim)) %>%
mutate(trial_cat = ifelse(str_detect(stimulus, ".jpg"), "speech","other")) %>%
filter(trial_cat == "speech") %>%
group_by(file_name) %>%
filter(trial > 5) %>%
mutate(trial_num = 1:n(),
subid = str_replace(str_replace(file_name,raw_data_path,""),
".txt",""))
frank_data
d
?C
d_moder1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time)) %>%
group_by(subid,trial_type,method,lab) %>%
summarise(log_lt = mean(log_lt)) %>%
group_by(subid,method,lab) %>%
filter(n() == 2) %>%
summarize(log_lt_diff = log_lt[trial_type == "IDS"] - log_lt[trial_type == "ADS"])
d_moder1
contrasts(d_moder1$method)
d_moder1$method <- as.factor(d_moder1$method)
contrasts(d_moder1$method)
contrasts(d_moder1$method) <- contr.sum(3)
contrasts(d_moder1$method)
summary(lmer(log_lt_diff ~ method + (1|lab), data = d_moder1))
d_moder1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time)) %>%
group_by(subid,trial_type,method,lab) %>%
summarise(log_lt = mean(log_lt)) %>%
group_by(subid,method,lab) %>%
filter(n() == 2) %>%
summarize(log_lt_diff = log_lt[trial_type == "IDS"] - log_lt[trial_type == "ADS"])
summary(lmer(log_lt_diff ~ method + (1|lab), data = d_moder1))
d_moder1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time)) %>%
group_by(subid,trial_type,method,lab) %>%
summarise(log_lt = mean(log_lt)) %>%
group_by(subid,method,lab) %>%
filter(n() == 2) %>%
summarize(log_lt_diff = log_lt[trial_type == "IDS"] - log_lt[trial_type == "ADS"])
summary(lmer(log_lt_diff ~ method + (1|lab), data = d_moder1))
d_moder1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time),AgeC = (age_days - mean(age_days))/sd(age_days)) %>%
group_by(subid,trial_type,method,lab,age_days) %>%
summarise(log_lt = mean(log_lt)) %>%
group_by(subid,method,lab,age_days) %>%
filter(n() == 2) %>%
summarize(log_lt_diff = log_lt[trial_type == "IDS"] - log_lt[trial_type == "ADS"])
summary(lmer(log_lt_diff ~ method*AgeC + (1+AgeC|lab), data = d_moder1))
d_moder1
library(retimes)
library(rstan)
library(ggplot2)
library(retimes)
library(rstan)
library(ggplot2)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
set.seed(123)
ads <- read.csv("exp2_adults.csv")
fives <- read.csv("exp2_fives.csv")
threes <- read.csv("exp2_threes.csv")
ads$Age <- "Adult"
fives$Age <- "Five"
threes$Age <- "Three"
tt <- rbind(ads,threes,fives)
tt$Age <- as.factor(tt$Age)
tt$Subject <- paste(tt$Age,tt$Subject, sep = "")
tt<- subset(tt, RT.ms <= 8000 & RT.ms >= -1000)
# I should really try with a lower cutoff. 4s? Done now; doesn't improve fit.
tt$rt <- tt$RT.ms
tt$N_Early <- ifelse(tt$Early.Late == "early",0,1)
tt$N_Pred <- ifelse(tt$Pred == "Pred",0,1)
tt$N_AgeFive <- model.matrix(~tt$Age)[,2]
tt$N_AgeThree <- model.matrix(~tt$Age)[,3]
#tt$N_AgeThree <- ifelse(tt$Age == "Adult",0,1)#model.matrix(~tt$Age)[,2]
tt$N_E_P_Interact <- tt$N_Pred * tt$N_Early
tt$N_Early_AgeFive_Interact <-  tt$N_Early * tt$N_AgeFive
tt$N_Early_AgeThree_Interact <- tt$N_Early * tt$N_AgeThree
tt$N_Pred_AgeFive_Interact <- tt$N_Pred * tt$N_AgeFive
tt$N_Pred_AgeThree_Interact <- tt$N_Pred * tt$N_AgeThree
tt$N_Early_Pred_AgeFive_Interact <- tt$N_Early * tt$N_Pred * tt$N_AgeFive
tt$N_Early_Pred_AgeThree_Interact <- tt$N_Early * tt$N_Pred * tt$N_AgeThree
# tt$rt_scale <- (tt$rt - mean(tt$rt,na.rm = T))/sd(tt$rt, na.rm = T)
tt$rt <- (tt$rt - mean(tt$rt))/(2*sd(tt$rt))
tt$scale_character_length <- (tt$CharacterLength.ms - mean(tt$CharacterLength.ms))/(2*sd(tt$CharacterLength.ms))
ggplot(tt,aes(x=rt,..density..,col=Pred))+ geom_freqpoly(alpha=1,lwd =1.5, bins = 50)+xlab("Response Time (ms)")+facet_wrap(Early.Late ~ Age) + xlim(c(-2,4))
# For some reason, model won't converge with RTs above zero?
#tt$rt <- tt$rt + abs(min(tt$rt))
# Fit Ex-Gaussian using ML (retimes library)
eg_ml <- timefit(tt$rt)
print(eg_ml)
stanDat_full <- list(rt = tt$rt,
factor1 = tt$N_Early,
factor2 = tt$N_Pred,
factor3 = tt$N_AgeFive,
factor4 = tt$N_AgeThree,
factor5 = tt$N_E_P_Interact,
factor6 = tt$N_Early_AgeFive_Interact,
factor6a = tt$N_Early_AgeThree_Interact,
factor7 = tt$N_Pred_AgeFive_Interact,
factor7a = tt$N_Pred_AgeThree_Interact,
factor8 = tt$N_Early_Pred_AgeFive_Interact,
factor8a = tt$N_Early_Pred_AgeThree_Interact,
factor9 = tt$scale_character_length,
N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan_exp <- stan(file="fixEf_Age_and_Conds_transf_expt2.stan",
data=stanDat_full, iter = 50)
setwd("~/GitHub/iPad_TurnTaking/DistrAnalyses/STAN_Analysis/Expt2_FullAnalysis")
library(retimes)
library(rstan)
library(ggplot2)
library(retimes)
library(rstan)
library(ggplot2)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
set.seed(123)
ads <- read.csv("exp2_adults.csv")
fives <- read.csv("exp2_fives.csv")
threes <- read.csv("exp2_threes.csv")
ads$Age <- "Adult"
fives$Age <- "Five"
threes$Age <- "Three"
tt <- rbind(ads,threes,fives)
tt$Age <- as.factor(tt$Age)
tt$Subject <- paste(tt$Age,tt$Subject, sep = "")
tt<- subset(tt, RT.ms <= 8000 & RT.ms >= -1000)
# I should really try with a lower cutoff. 4s? Done now; doesn't improve fit.
tt$rt <- tt$RT.ms
tt$N_Early <- ifelse(tt$Early.Late == "early",0,1)
tt$N_Pred <- ifelse(tt$Pred == "Pred",0,1)
tt$N_AgeFive <- model.matrix(~tt$Age)[,2]
tt$N_AgeThree <- model.matrix(~tt$Age)[,3]
#tt$N_AgeThree <- ifelse(tt$Age == "Adult",0,1)#model.matrix(~tt$Age)[,2]
tt$N_E_P_Interact <- tt$N_Pred * tt$N_Early
tt$N_Early_AgeFive_Interact <-  tt$N_Early * tt$N_AgeFive
tt$N_Early_AgeThree_Interact <- tt$N_Early * tt$N_AgeThree
tt$N_Pred_AgeFive_Interact <- tt$N_Pred * tt$N_AgeFive
tt$N_Pred_AgeThree_Interact <- tt$N_Pred * tt$N_AgeThree
tt$N_Early_Pred_AgeFive_Interact <- tt$N_Early * tt$N_Pred * tt$N_AgeFive
tt$N_Early_Pred_AgeThree_Interact <- tt$N_Early * tt$N_Pred * tt$N_AgeThree
# tt$rt_scale <- (tt$rt - mean(tt$rt,na.rm = T))/sd(tt$rt, na.rm = T)
tt$rt <- (tt$rt - mean(tt$rt))/(2*sd(tt$rt))
tt$scale_character_length <- (tt$CharacterLength.ms - mean(tt$CharacterLength.ms))/(2*sd(tt$CharacterLength.ms))
ggplot(tt,aes(x=rt,..density..,col=Pred))+ geom_freqpoly(alpha=1,lwd =1.5, bins = 50)+xlab("Response Time (ms)")+facet_wrap(Early.Late ~ Age) + xlim(c(-2,4))
# For some reason, model won't converge with RTs above zero?
#tt$rt <- tt$rt + abs(min(tt$rt))
# Fit Ex-Gaussian using ML (retimes library)
eg_ml <- timefit(tt$rt)
print(eg_ml)
stanDat_full <- list(rt = tt$rt,
factor1 = tt$N_Early,
factor2 = tt$N_Pred,
factor3 = tt$N_AgeFive,
factor4 = tt$N_AgeThree,
factor5 = tt$N_E_P_Interact,
factor6 = tt$N_Early_AgeFive_Interact,
factor6a = tt$N_Early_AgeThree_Interact,
factor7 = tt$N_Pred_AgeFive_Interact,
factor7a = tt$N_Pred_AgeThree_Interact,
factor8 = tt$N_Early_Pred_AgeFive_Interact,
factor8a = tt$N_Early_Pred_AgeThree_Interact,
factor9 = tt$scale_character_length,
N = nrow(tt), J = nlevels(as.factor(tt$Subject)), Subj = as.integer(as.factor(tt$Subject)))
eg_stan_exp <- stan(file="fixEf_Age_and_Conds_transf_expt2.stan",
data=stanDat_full, iter = 50)
print(eg_stan_exp, pars = c("beta0","beta","beta_s0","beta_s","beta_t0","beta_t"), probs = c(0.025,0.5,0.975))
